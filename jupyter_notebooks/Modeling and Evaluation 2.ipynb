{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation Notebook Transfer Learning**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/train\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/test\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/validation\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Images distribution plot in train, validation, and test set.\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels.\n",
        "* Machine learning model creation and training.\n",
        "* Save model.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "* Prediction on the random image file.\n",
        "\n",
        "## Additional Comments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-10-30 17:23:00.535002: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-10-30 17:23:00.571052: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import array_to_img, img_to_array, load_img\n",
        "from keras.applications.vgg16 import VGG16"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Set input directories\n",
        "Set train, validation and test paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/brain-tumor-mri-dataset/mri-images'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v2'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v2'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of images in train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([])\n",
        "data_list = []\n",
        "\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        # Collect data in a list of dictionaries\n",
        "        data_list.append({\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))\n",
        "        })\n",
        "\n",
        "        print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir + '/' + folder + '/' + label))} images\")\n",
        "\n",
        "# Convert list of dictionaries to a DataFrame\n",
        "df_freq = pd.DataFrame(data_list)\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing\n",
        "batch_size = 32\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "                                        rescale=1./255,\n",
        "                                        rotation_range=30,\n",
        "                                        brightness_range=(0.8, 1.2),\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1,\n",
        "                                        shear_range=15,\n",
        "                                        zoom_range=0.1,\n",
        "                                        channel_shift_range=0.2,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=False,\n",
        "                                        fill_mode=\"nearest\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Preprocessing for Testing Data (without augmentation, only rescaling)\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(\n",
        "                                                                test_path,\n",
        "                                                                target_size=(150, 150),\n",
        "                                                                batch_size=batch_size,\n",
        "                                                                class_mode='categorical'\n",
        "                                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# applying the generator to training data with constant seed\n",
        "train_set = augmented_image_data.flow_from_directory(\n",
        "                                                    train_path,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    shuffle=True)\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# applying the generator to training data with constant seed\n",
        "train_set = augmented_image_data.flow_from_directory(\n",
        "                                                    train_path,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    shuffle=True)\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of images from the generator\n",
        "x_batch, y_batch = next(train_set)  # Extract the first batch of augmented images\n",
        "\n",
        "# Display the first 5 images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.title(list(train_set.class_indices.keys())[np.argmax(y_batch[i])])  # Display the class name\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of images from the generator\n",
        "x_batch, y_batch = next(validation_set)  # Extract the first batch of augmented images\n",
        "\n",
        "# Display the first 5 images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.title(list(validation_set.class_indices.keys())[np.argmax(y_batch[i])])\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML model\n",
        "Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating an object of VGG16 Model to use it as a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_base = VGG16(\n",
        "    weights='imagenet', # weight of the trained model\n",
        "    include_top = False, # disables the Dense layers and output layer\n",
        "    input_shape=image_shape\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Freez the Trainable parameters of the trained model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_base.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "show the summary of the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conv_base.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data Classifications\n",
        "CLASS_TYPES = ['pituitary', 'notumor', 'meningioma', 'glioma']\n",
        "N_TYPES = len(CLASS_TYPES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    \"\"\"\n",
        "    Creates and compiles a TensorFlow model.\n",
        "\n",
        "    Parameters:\n",
        "    - conv_base: The convolutional base to use as a feature extractor.\n",
        "    - N_TYPES: The number of output classes.\n",
        "\n",
        "    Returns:\n",
        "    - model: A compiled TensorFlow Keras model.\n",
        "    \"\"\"\n",
        "    model = Sequential()\n",
        "\n",
        "    model.add(conv_base)\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(256,activation='relu'))\n",
        "    model.add(Dense(N_TYPES, activation=\"softmax\"))\n",
        "\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the function and display the model summary\n",
        "model = create_tf_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "# Visualize the model\n",
        "model_str = visualkeras.layered_view(model, legend=True, max_xy=300, legend_text_spacing_offset=20)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(model_str)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig(f'{file_path}/model_visualization.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Stop training if loss doesn't keep decreasing.\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-9, patience=8, restore_best_weights=True, verbose=True)\n",
        "model_rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=20,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop, model_rlr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "saving the\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v2/brain_tumor_detector.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reload the model to ensure fresh state\n",
        "model = keras.models.load_model('outputs/v2/brain_tumor_detector.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(test_set, steps=test_set.samples // batch_size)\n",
        "print(f\"Test Loss: {loss:.5f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save evaluation pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving the evaluation results in a dictionary\n",
        "evaluation = {\n",
        "    'loss': loss,\n",
        "    'accuracy': accuracy\n",
        "}\n",
        "\n",
        "# Saving the evaluation results using joblib\n",
        "joblib.dump(value=evaluation, filename=\"outputs/v2/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on new data\n",
        "Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# Get the next batch from the test generator\n",
        "batch_images, batch_labels = next(test_set)\n",
        "\n",
        "# Extract the first image from the batch\n",
        "image, label = batch_images[3], batch_labels[0]\n",
        "image_tensor = np.expand_dims(image, axis=0)\n",
        "\n",
        "# Get the class indices from the test set\n",
        "class_indices = test_set.class_indices\n",
        "\n",
        "# Convert the one-hot encoded label to the class name\n",
        "label_name = [k for k, v in class_indices.items() if np.argmax(label) == v][0]\n",
        "\n",
        "# Display the class name\n",
        "print(f\"Class name of the first image: {label_name}\")\n",
        "print(f'Shape {image_tensor.shape}')\n",
        "\n",
        "# Display the image\n",
        "array_to_img(image_tensor[0])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_set, steps=test_set.samples // batch_size)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes from test set\n",
        "true_classes = test_set.classes\n",
        "\n",
        "# Get class names\n",
        "class_indices_train_list = list(train_set.class_indices.keys())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = sklearn_confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks(ticks=np.arange(len(class_indices_train_list)) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], ha='center')\n",
        "plt.yticks(ticks=np.arange(len(class_indices_train_list)) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], va='center')\n",
        "\n",
        "plt.savefig('outputs/v2/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "# Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this notebook, I have implemented a deep learning model using the VGG16 architecture for the brain tumor detection task. I use it as pretrained model, I freezed all the convolutional layers removed the dense and output layers, I then create at the end my own dense layers for the model, this model including early stopping and learning rate reduction. Finally, we evaluate the model on the test set and visualize the results.\n",
        "\n",
        "The next steps for further improvement and deployment of this model include:\n",
        "1. Fine-tuning the model: Experiment with different hyperparameters and architectures like unblock the last layer of this model and train it to improve performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
