{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# **Modelling and Evaluation Notebook**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1:\n",
        "    * Write here your notebook objective, for example, \"Fetch data from Kaggle and save as raw data\", or \"engineer features for modelling\"\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/train\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/test\n",
        "* inputs/brain-tumor-mri-dataset/mri-images/validation\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Images distribution plot in train, validation, and test set.\n",
        "* Image augmentation.\n",
        "* Class indices to change prediction inference in labels.\n",
        "* Machine learning model creation and training.\n",
        "* Save model.\n",
        "* Learning curve plot for model performance.\n",
        "* Model evaluation on pickle file.\n",
        "* Prediction on the random image file.\n",
        "\n",
        "## Additional Comments\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the regular packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from matplotlib.image import imread\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "work_dir = os.getcwd()\n",
        "work_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "## Set input directories\n",
        "Set train, validation and test paths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_data_dir = 'inputs/brain-tumor-mri-dataset/mri-images'\n",
        "train_path = my_data_dir + '/train'\n",
        "val_path = my_data_dir + '/validation'\n",
        "test_path = my_data_dir + '/test'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Set output directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "version = 'v1'\n",
        "file_path = f'outputs/{version}'\n",
        "\n",
        "if 'outputs' in os.listdir(work_dir) and version in os.listdir(work_dir + '/outputs'):\n",
        "    print('Old version is already available create a new version.')\n",
        "    pass\n",
        "else:\n",
        "    os.makedirs(name=file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "labels = os.listdir(train_path)\n",
        "\n",
        "print(\n",
        "    f\"Project Labels: {labels}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set image shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Import saved image shape embedding\n",
        "import joblib\n",
        "version = 'v1'\n",
        "image_shape = joblib.load(filename=f\"outputs/{version}/image_shape.pkl\")\n",
        "image_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Number of images in train, test and validation data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_freq = pd.DataFrame([])\n",
        "data_list = []\n",
        "\n",
        "for folder in ['train', 'validation', 'test']:\n",
        "    for label in labels:\n",
        "        # Collect data in a list of dictionaries\n",
        "        data_list.append({\n",
        "            'Set': folder,\n",
        "            'Label': label,\n",
        "            'Frequency': int(len(os.listdir(my_data_dir + '/' + folder + '/' + label)))\n",
        "        })\n",
        "\n",
        "        print(f\"* {folder} - {label}: {len(os.listdir(my_data_dir + '/' + folder + '/' + label))} images\")\n",
        "\n",
        "# Convert list of dictionaries to a DataFrame\n",
        "df_freq = pd.DataFrame(data_list)\n",
        "\n",
        "print(\"\\n\")\n",
        "sns.set_style(\"whitegrid\")\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(data=df_freq, x='Set', y='Frequency', hue='Label')\n",
        "plt.savefig(f'{file_path}/labels_distribution.png', bbox_inches='tight', dpi=150)\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Image data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Global Variables and Random Seeds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global variables\n",
        "SAVE = False\n",
        "SEED = 111\n",
        "\n",
        "# Setting seed for consistent results\n",
        "tf.keras.utils.set_random_seed(SEED)\n",
        "tf.random.set_seed(SEED)\n",
        "np.random.seed(SEED)\n",
        "\n",
        "# Data Classifications\n",
        "CLASS_TYPES = ['pituitary', 'notumor', 'meningioma', 'glioma']\n",
        "N_TYPES = len(CLASS_TYPES)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "Initialize ImageDataGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Data augmentation and preprocessing\n",
        "augmented_image_data = ImageDataGenerator(\n",
        "                                        rescale=1./255,\n",
        "                                        rotation_range=30,\n",
        "                                        brightness_range=(0.8, 1.2),\n",
        "                                        width_shift_range=0.1,\n",
        "                                        height_shift_range=0.1,\n",
        "                                        shear_range=15,\n",
        "                                        zoom_range=0.1,\n",
        "                                        channel_shift_range=0.2,\n",
        "                                        horizontal_flip=True,\n",
        "                                        vertical_flip=False,\n",
        "                                        fill_mode=\"nearest\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment training image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# applying the generator to training data with constant seed\n",
        "batch_size = 32\n",
        "train_set = augmented_image_data.flow_from_directory(\n",
        "                                                    train_path,\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    target_size=image_shape[:2],\n",
        "                                                    class_mode=\"categorical\",\n",
        "                                                    shuffle=True,\n",
        "                                                    seed=SEED)\n",
        "train_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment validation image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "validation_set = ImageDataGenerator(rescale=1./255).flow_from_directory(val_path,\n",
        "                                                                        batch_size=batch_size,\n",
        "                                                                        target_size=image_shape[:2],\n",
        "                                                                        class_mode='categorical',\n",
        "                                                                        shuffle=False,\n",
        "                                                                        seed=SEED)\n",
        "\n",
        "validation_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Augment test image dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# applying the generator to testing data with constant seed\n",
        "test_set = ImageDataGenerator(rescale=1./255).flow_from_directory(test_path,\n",
        "                                                                  batch_size=batch_size,\n",
        "                                                                  target_size=image_shape[:2],\n",
        "                                                                  class_mode='categorical',\n",
        "                                                                  shuffle=False,\n",
        "                                                                  seed=SEED)\n",
        "\n",
        "test_set.class_indices"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented training image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of images from the generator\n",
        "x_batch, y_batch = next(train_set)  # Extract the first batch of augmented images\n",
        "\n",
        "# Display the first 5 images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.title(list(train_set.class_indices.keys())[np.argmax(y_batch[i])])  # Display the class name\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented validation images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of images from the generator\n",
        "x_batch, y_batch = next(validation_set)  # Extract the first batch of augmented images\n",
        "\n",
        "# Display the first 5 images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.title(list(validation_set.class_indices.keys())[np.argmax(y_batch[i])])\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot augmented test images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get a batch of images from the generator\n",
        "x_batch, y_batch = next(test_set)  # Extract the first batch of augmented images\n",
        "\n",
        "# Display the first 5 images\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(5):\n",
        "    plt.subplot(1, 5, i + 1)\n",
        "    plt.title(list(test_set.class_indices.keys())[np.argmax(y_batch[i])])\n",
        "    plt.imshow(x_batch[i])\n",
        "    plt.axis('off')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Save class_indices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "joblib.dump(value=train_set.class_indices,\n",
        "            filename=f\"{file_path}/class_indices.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### ML model\n",
        "Import model packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense, Conv2D, MaxPooling2D, Input, BatchNormalization\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tf_model():\n",
        "    model = Sequential()\n",
        "    model.add(Input(shape=image_shape))\n",
        "    \n",
        "    model.add(Conv2D(filters=32, kernel_size=(3, 3), activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu', ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Flatten())\n",
        "\n",
        "    model.add(Dense(128, activation=\"relu\"))\n",
        "    model.add(Dropout(0.5, seed=SEED))\n",
        "    model.add(Dense(N_TYPES, activation=\"softmax\"))\n",
        "    \n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics= ['accuracy'])\n",
        "    \n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Call the function and display the model summary\n",
        "model = create_tf_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import visualkeras\n",
        "\n",
        "# Visualize the model\n",
        "model_str = visualkeras.layered_view(model, legend=True, max_xy=300, legend_text_spacing_offset=20)\n",
        "\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(model_str)\n",
        "plt.axis('off')\n",
        "\n",
        "plt.savefig(f'{file_path}/model_visualization.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Early Stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "# Stop training if loss doesn't keep decreasing.\n",
        "early_stop = EarlyStopping(monitor='val_loss', min_delta=1e-9, patience=8, restore_best_weights=True, verbose=True)\n",
        "model_rlr = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose=True)\n",
        "\n",
        "# Increase steps_per_epoch to repeat the dataset more times per epoch\n",
        "steps_per_epoch = (len(train_set.classes) // batch_size) * 3  # Repeat dataset 3 times per epoch (adjust multiplier as needed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Fit model for model training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = create_tf_model()\n",
        "model.fit(train_set,\n",
        "          epochs=25,\n",
        "          steps_per_epoch=steps_per_epoch,\n",
        "          validation_data=validation_set,\n",
        "          callbacks=[early_stop, model_rlr])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "saving the\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('outputs/v1/brain_tumor_detector.keras')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Performace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "losses = pd.DataFrame(model.history.history)\n",
        "\n",
        "sns.set_style(\"whitegrid\")\n",
        "losses[['loss', 'val_loss']].plot(style='.-')\n",
        "plt.title(\"Loss\")\n",
        "plt.savefig(f'{file_path}/model_training_losses.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n\")\n",
        "losses[['accuracy', 'val_accuracy']].plot(style='.-')\n",
        "plt.title(\"Accuracy\")\n",
        "plt.savefig(f'{file_path}/model_training_acc.png',\n",
        "            bbox_inches='tight', dpi=150)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Evaluation\n",
        "Load saved model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Reload the model to ensure fresh state\n",
        "model = load_model('outputs/v1/brain_tumor_detector.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Evaluate model on test set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluating the model\n",
        "loss, accuracy = model.evaluate(test_set, steps=test_set.samples // batch_size)\n",
        "print(f\"Test Loss: {loss:.5f}\")\n",
        "print(f\"Test Accuracy: {accuracy:.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Save evaluation pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Saving the evaluation results in a dictionary\n",
        "evaluation = {\n",
        "    'loss': loss,\n",
        "    'accuracy': accuracy\n",
        "}\n",
        "\n",
        "# Saving the evaluation results using joblib\n",
        "joblib.dump(value=evaluation, filename=\"outputs/v1/evaluation.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Predict on new data\n",
        "Load a random image as PIL"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load a random image as PIL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "pointer = 66\n",
        "label = labels[2]\n",
        "\n",
        "pil_image = image.load_img(test_path + '/' + label + '/' + os.listdir(test_path+'/' + label)[pointer],\n",
        "                           target_size=image_shape, color_mode='rgb')\n",
        "print(f'Image shape: {pil_image.size}, Image mode: {pil_image.mode}')\n",
        "pil_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Convert image to array and prepare for prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_image = image.img_to_array(pil_image)\n",
        "my_image = np.expand_dims(my_image, axis=0)/255\n",
        "print(my_image.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Predict class probabilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pred_proba = model.predict(my_image)[0, 0]\n",
        "\n",
        "target_map = {v: k for k, v in train_set.class_indices.items()}\n",
        "pred_class = target_map[pred_proba > 0.5]\n",
        "\n",
        "if pred_class == target_map[0]:\n",
        "    pred_proba = 1 - pred_proba\n",
        "\n",
        "print(pred_proba)\n",
        "print(pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix as sklearn_confusion_matrix\n",
        "\n",
        "# Make predictions on the test set\n",
        "predictions = model.predict(test_set, steps=test_set.samples // batch_size)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Get true classes from test set\n",
        "true_classes = test_set.classes\n",
        "\n",
        "# Get class names\n",
        "class_indices_train_list = list(train_set.class_indices.keys())\n",
        "\n",
        "# Compute confusion matrix\n",
        "cm = sklearn_confusion_matrix(true_classes, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.xticks(ticks=np.arange(len(class_indices_train_list)) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], ha='center')\n",
        "plt.yticks(ticks=np.arange(len(class_indices_train_list)) + 0.5,\n",
        "           labels=[name.title() for name in class_indices_train_list], va='center')\n",
        "\n",
        "plt.savefig('outputs/v1/confusion_matrix.png', bbox_inches='tight', dpi=150)\n",
        "\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltNetd085qHf"
      },
      "source": [
        "\n",
        "## Conclusion"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook is for modeling and evaluation of a brain tumor detector . It covers data preprocessing, model creation, training, evaluation, prediction, and confusion matrix generation. The script also includes data augmentation, early stopping, and learning rate reduction to improve the model's performance."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
